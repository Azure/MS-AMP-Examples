diff --git a/config.py b/config.py
index 1671ec3..be7c6fd 100644
--- a/config.py
+++ b/config.py
@@ -260,6 +260,12 @@ _C.LOCAL_RANK = 0
 _C.FUSED_WINDOW_PROCESS = False
 _C.FUSED_LAYERNORM = False
 
+# ms-amp
+_C.ENABLE_MSAMP = False
+_C.MSAMP_OPT_LEVEL = 'O2'
+
+# te-fp8
+_C.ENABLE_TEFP8 = False
 
 def _update_config_from_file(config, cfg_file):
     config.defrost()
@@ -333,6 +339,16 @@ def update_config(config, args):
     if _check_args('optim'):
         config.TRAIN.OPTIMIZER.NAME = args.optim
 
+    ## msamp
+    if _check_args('enable_msamp'):
+        config.ENABLE_MSAMP = args.enable_msamp
+    if _check_args('msamp_opt_level'):
+        config.MSAMP_OPT_LEVEL = args.msamp_opt_level
+
+    # te-fp8
+    if _check_args('enable_tefp8'):
+        config.ENABLE_TEFP8 = args.enable_tefp8
+
     # set local rank for distributed training
     config.LOCAL_RANK = args.local_rank
 
diff --git a/configs/swin/swin_giant_patch4_window7_224.yaml b/configs/swin/swin_giant_patch4_window7_224.yaml
new file mode 100644
index 0000000..67b4476
--- /dev/null
+++ b/configs/swin/swin_giant_patch4_window7_224.yaml
@@ -0,0 +1,9 @@
+MODEL:
+  TYPE: swin
+  NAME: swin_giant_patch4_window7_224
+  DROP_PATH_RATE: 0.5
+  SWIN:
+    EMBED_DIM: 448
+    DEPTHS: [ 2, 2, 18, 2 ]
+    NUM_HEADS: [ 14, 28, 56, 112 ]
+    WINDOW_SIZE: 7
\ No newline at end of file
diff --git a/main.py b/main.py
index 84230ea..a40369e 100644
--- a/main.py
+++ b/main.py
@@ -19,6 +19,7 @@ import torch.distributed as dist
 
 from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy
 from timm.utils import accuracy, AverageMeter
+import msamp
 
 from config import get_config
 from models import build_model
@@ -29,6 +30,10 @@ from logger import create_logger
 from utils import load_checkpoint, load_pretrained, save_checkpoint, NativeScalerWithGradNormCount, auto_resume_helper, \
     reduce_tensor
 
+import sys
+sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), '../../'))
+
+from common.te_utils import replace_with_telinear, TeUtils
 
 def parse_option():
     parser = argparse.ArgumentParser('Swin Transformer training and evaluation script', add_help=False)
@@ -64,7 +69,7 @@ def parse_option():
     parser.add_argument('--throughput', action='store_true', help='Test throughput only')
 
     # distributed training
-    parser.add_argument("--local_rank", type=int, required=True, help='local rank for DistributedDataParallel')
+    parser.add_argument("--local_rank", type=int, help='local rank for DistributedDataParallel')
 
     # for acceleration
     parser.add_argument('--fused_window_process', action='store_true',
@@ -73,9 +78,18 @@ def parse_option():
     ## overwrite optimizer in config (*.yaml) if specified, e.g., fused_adam/fused_lamb
     parser.add_argument('--optim', type=str,
                         help='overwrite optimizer if provided, can be adamw/sgd/fused_adam/fused_lamb.')
+    # ms-amp
+    parser.add_argument('--enable-msamp', action='store_true', default=False, help='enable MS-AMP')
+    parser.add_argument('--msamp-opt-level', type=str, default='O1', help='MS-AMP optimization level')
+
+    # te-fp8
+    parser.add_argument('--enable-tefp8', action='store_true', default=False, help='enable TE-FP8')
 
     args, unparsed = parser.parse_known_args()
 
+    if args.local_rank is None and 'LOCAL_RANK' in os.environ:
+        args.local_rank = int(os.environ['LOCAL_RANK'])
+
     config = get_config(args)
 
     return args, config
@@ -88,6 +102,10 @@ def main(config):
     model = build_model(config)
     logger.info(str(model))
 
+    # get flops of the model.
+    model_flops = model.flops()
+    args.model_flops = model_flops
+
     n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)
     logger.info(f"number of params: {n_parameters}")
     if hasattr(model, 'flops'):
@@ -95,9 +113,22 @@ def main(config):
         logger.info(f"number of GFLOPs: {flops / 1e9}")
 
     model.cuda()
+
+    if config.ENABLE_TEFP8:
+        logger.info('te-fp8 is enabled')
+        model = replace_with_telinear(model)
+
     model_without_ddp = model
 
     optimizer = build_optimizer(config, model)
+    if config.ENABLE_MSAMP:
+        logger.info(f"msamp is enabled, opt level is {config.MSAMP_OPT_LEVEL}")
+        model, optimizer = msamp.initialize(model, optimizer, config.MSAMP_OPT_LEVEL)
+
+    if dist.get_rank() == 0:
+        logger.info(f'type of optimizer is {optimizer}')
+        logger.info(f'model is {model}')
+
     model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[config.LOCAL_RANK], broadcast_buffers=False)
     loss_scaler = NativeScalerWithGradNormCount()
 
@@ -177,6 +208,8 @@ def train_one_epoch(config, model, criterion, data_loader, optimizer, epoch, mix
 
     start = time.time()
     end = time.time()
+
+    autocast_context = TeUtils.get_autocast(config.AMP_ENABLE, config.ENABLE_TEFP8)
     for idx, (samples, targets) in enumerate(data_loader):
         samples = samples.cuda(non_blocking=True)
         targets = targets.cuda(non_blocking=True)
@@ -184,14 +217,14 @@ def train_one_epoch(config, model, criterion, data_loader, optimizer, epoch, mix
         if mixup_fn is not None:
             samples, targets = mixup_fn(samples, targets)
 
-        with torch.cuda.amp.autocast(enabled=config.AMP_ENABLE):
+        with autocast_context():
             outputs = model(samples)
         loss = criterion(outputs, targets)
         loss = loss / config.TRAIN.ACCUMULATION_STEPS
 
         # this attribute is added by timm on one optimizer (adahessian)
         is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order
-        grad_norm = loss_scaler(loss, optimizer, clip_grad=config.TRAIN.CLIP_GRAD,
+        grad_norm = loss_scaler(loss, model, optimizer, clip_grad=config.TRAIN.CLIP_GRAD,
                                 parameters=model.parameters(), create_graph=is_second_order,
                                 update_grad=(idx + 1) % config.TRAIN.ACCUMULATION_STEPS == 0)
         if (idx + 1) % config.TRAIN.ACCUMULATION_STEPS == 0:
@@ -207,19 +240,26 @@ def train_one_epoch(config, model, criterion, data_loader, optimizer, epoch, mix
         scaler_meter.update(loss_scale_value)
         batch_time.update(time.time() - end)
         end = time.time()
-
+        throughput_per_gpu = args.batch_size / batch_time.val
+        throughput = dist.get_world_size() * throughput_per_gpu
+        throughput_avg = dist.get_world_size() * args.batch_size / batch_time.avg
         if idx % config.PRINT_FREQ == 0:
             lr = optimizer.param_groups[0]['lr']
             wd = optimizer.param_groups[0]['weight_decay']
             memory_used = torch.cuda.max_memory_allocated() / (1024.0 * 1024.0)
             etas = batch_time.avg * (num_steps - idx)
+            ratio = 3 if config.TRAIN.USE_CHECKPOINT else 4
+            # First mutiply by ratio: 1 for forward, 2 for backward, 1 for activation checkpoint. Then multiply by 2: 1MACs = 2FLOPs
+            tflops = ratio * 2 * args.model_flops * throughput_per_gpu / 1e12
             logger.info(
                 f'Train: [{epoch}/{config.TRAIN.EPOCHS}][{idx}/{num_steps}]\t'
                 f'eta {datetime.timedelta(seconds=int(etas))} lr {lr:.6f}\t wd {wd:.4f}\t'
                 f'time {batch_time.val:.4f} ({batch_time.avg:.4f})\t'
+                f'throughput {throughput:.2f} ({throughput_avg: .2f})\t'
                 f'loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\t'
                 f'grad_norm {norm_meter.val:.4f} ({norm_meter.avg:.4f})\t'
                 f'loss_scale {scaler_meter.val:.4f} ({scaler_meter.avg:.4f})\t'
+                f'tflops {tflops:.2f}\t'
                 f'mem {memory_used:.0f}MB')
     epoch_time = time.time() - start
     logger.info(f"EPOCH {epoch} training takes {datetime.timedelta(seconds=int(epoch_time))}")
@@ -236,12 +276,13 @@ def validate(config, data_loader, model):
     acc5_meter = AverageMeter()
 
     end = time.time()
+    autocast_context = TeUtils.get_autocast(config.AMP_ENABLE, config.ENABLE_TEFP8)
     for idx, (images, target) in enumerate(data_loader):
         images = images.cuda(non_blocking=True)
         target = target.cuda(non_blocking=True)
 
         # compute output
-        with torch.cuda.amp.autocast(enabled=config.AMP_ENABLE):
+        with autocast_context():
             output = model(images)
 
         # measure accuracy and record loss
diff --git a/models/build.py b/models/build.py
index c37384d..772e68b 100644
--- a/models/build.py
+++ b/models/build.py
@@ -50,6 +50,8 @@ def build_model(config, is_pretrain=False):
                                 patch_norm=config.MODEL.SWIN.PATCH_NORM,
                                 use_checkpoint=config.TRAIN.USE_CHECKPOINT,
                                 fused_window_process=config.FUSED_WINDOW_PROCESS)
+        if config.ENABLE_MSAMP or config.ENABLE_TEFP8:
+            model.head.use_fp32_linear = True
     elif model_type == 'swinv2':
         model = SwinTransformerV2(img_size=config.DATA.IMG_SIZE,
                                   patch_size=config.MODEL.SWINV2.PATCH_SIZE,
diff --git a/utils.py b/utils.py
index eb607cf..7be4dd6 100644
--- a/utils.py
+++ b/utils.py
@@ -8,8 +8,8 @@
 import os
 import torch
 import torch.distributed as dist
-from torch._six import inf
-
+from torch import inf
+from msamp import clip_grad_norm_
 
 def load_checkpoint(config, model, optimizer, lr_scheduler, loss_scaler, logger):
     logger.info(f"==============> Resuming form {config.MODEL.RESUME}....................")
@@ -198,13 +198,15 @@ class NativeScalerWithGradNormCount:
     def __init__(self):
         self._scaler = torch.cuda.amp.GradScaler()
 
-    def __call__(self, loss, optimizer, clip_grad=None, parameters=None, create_graph=False, update_grad=True):
+    def __call__(self, loss, model, optimizer, clip_grad=None, parameters=None, create_graph=False, update_grad=True):
         self._scaler.scale(loss).backward(create_graph=create_graph)
         if update_grad:
             if clip_grad is not None:
+                if hasattr(optimizer, 'all_reduce_grads'):
+                    optimizer.all_reduce_grads(model)
                 assert parameters is not None
                 self._scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params in-place
-                norm = torch.nn.utils.clip_grad_norm_(parameters, clip_grad)
+                norm = clip_grad_norm_(parameters, clip_grad)
             else:
                 self._scaler.unscale_(optimizer)
                 norm = ampscaler_get_grad_norm(parameters)
