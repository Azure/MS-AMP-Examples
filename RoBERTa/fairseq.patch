diff --git a/fairseq/dataclass/configs.py b/fairseq/dataclass/configs.py
index 5fdfab38..e444294c 100644
--- a/fairseq/dataclass/configs.py
+++ b/fairseq/dataclass/configs.py
@@ -250,7 +250,12 @@ class CommonConfig(FairseqDataclass):
             "help": "path to run plasma_store, defaults to /tmp/plasma. Paths outside /tmp tend to fail."
         },
     )
-
+    # MS-AMP config
+    msamp: bool = field(default=False, metadata={"help": "use microsoft automatic mixed precision"})
+    msamp_opt_level: str = field(
+        default="O1",
+        metadata={"help": "microsoft automatic mixed precision optimization level"},
+    )
 
 @dataclass
 class DistributedTrainingConfig(FairseqDataclass):
diff --git a/fairseq/models/roberta/model.py b/fairseq/models/roberta/model.py
index d7ced919..02ce8e4f 100644
--- a/fairseq/models/roberta/model.py
+++ b/fairseq/models/roberta/model.py
@@ -473,6 +473,7 @@ class RobertaLMHead(nn.Module):
     def __init__(self, embed_dim, output_dim, activation_fn, weight=None):
         super().__init__()
         self.dense = nn.Linear(embed_dim, embed_dim)
+        self.dense.use_fp32_linear = True
         self.activation_fn = utils.get_activation_fn(activation_fn)
         self.layer_norm = LayerNorm(embed_dim)
 
diff --git a/fairseq/optim/adam.py b/fairseq/optim/adam.py
index 678ec7c6..f535ac12 100644
--- a/fairseq/optim/adam.py
+++ b/fairseq/optim/adam.py
@@ -16,7 +16,7 @@ from fairseq.dataclass import FairseqDataclass
 from fairseq.optim import FairseqOptimizer, register_optimizer
 from fairseq.optim.fused_adam import get_fused_adam_class
 from omegaconf import II, OmegaConf
-
+import msamp
 
 logger = logging.getLogger(__name__)
 
@@ -39,6 +39,8 @@ class FairseqAdamConfig(FairseqDataclass):
     # TODO common vars below in parent
     tpu: bool = II("common.tpu")
     lr: List[float] = II("optimization.lr")
+    msamp: bool = II("common.msamp")
+    msamp_opt_level: str = II("common.msamp_opt_level")
 
 
 @register_optimizer("adam", dataclass=FairseqAdamConfig)
@@ -58,7 +60,19 @@ class FairseqAdam(FairseqOptimizer):
             and fused_adam_cls is not None
             and torch.cuda.is_available()
         )
-        if getattr(cfg, "tpu", False):
+
+        if cfg.msamp:
+            logger.info(f"using LBAdamW, msamp opt level is {cfg.msamp_opt_level}")
+            if cfg.msamp_opt_level == 'O1':
+                self.optimizer_config['exp_avg_dtype'] = torch.float32
+                self.optimizer_config['exp_avg_sq_dtype'] = torch.float32
+            elif cfg.msamp_opt_level == 'O2':
+                self.optimizer_config['exp_avg_dtype'] = torch.uint8
+                self.optimizer_config['exp_avg_sq_dtype'] = torch.float16
+            else:
+                logger.warning(f"msamp opt level {cfg.msamp_opt_level} is not supported")
+            self._optimizer = LBAdamW(params, **self.optimizer_config)
+        elif getattr(cfg, "tpu", False):
             if self.cfg.fp16_adam_stats:
                 raise NotImplementedError("--fp16-adam-stats is only supported on GPU")
             # on TPUs we use the Adam defined here, since it
@@ -106,6 +120,10 @@ class FairseqAdam(FairseqOptimizer):
             dist.all_reduce(value["exp_avg"], op=dist.ReduceOp.SUM)
             dist.all_reduce(value["exp_avg_sq"], op=dist.ReduceOp.SUM)
 
+    def all_reduce_grads(self, model):
+        if self.cfg.msamp and hasattr(self._optimizer, "all_reduce_grads"):
+            self._optimizer.all_reduce_grads(model)
+        super().all_reduce_grads(model)
 
 class Adam(torch.optim.Optimizer):
     r"""Implements Adam algorithm.
@@ -237,3 +255,31 @@ class Adam(torch.optim.Optimizer):
                     p.data.copy_(p_data_fp32)
 
         return loss
+
+class LBAdamW(msamp.LBAdamW):
+    def __init__(
+        self,
+        params,
+        lr=1e-3,
+        betas=(0.9, 0.999),
+        eps=1e-8,
+        weight_decay=0,
+        amsgrad=False,
+        exp_avg_dtype=torch.uint8,
+        exp_avg_sq_dtype=torch.float16,
+    ):
+        defaults = dict(
+            lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad,
+            exp_avg_dtype=exp_avg_dtype, exp_avg_sq_dtype=exp_avg_sq_dtype
+        )
+        super().__init__(params, **defaults)
+
+    @property
+    def supports_memory_efficient_fp16(self):
+        # DO NOT USE MemoryEfficientFP16Optimizer
+        return False
+
+    @property
+    def supports_flat_params(self):
+        # since FP16 params with different scaling factor
+        return False
diff --git a/fairseq/optim/fairseq_optimizer.py b/fairseq/optim/fairseq_optimizer.py
index 7e541175..5fff9e04 100644
--- a/fairseq/optim/fairseq_optimizer.py
+++ b/fairseq/optim/fairseq_optimizer.py
@@ -7,6 +7,7 @@ import torch
 from fairseq import utils
 from fairseq.dataclass.utils import gen_parser_from_dataclass
 
+import msamp
 
 class FairseqOptimizer(object):
     def __init__(self, cfg):
@@ -109,6 +110,8 @@ class FairseqOptimizer(object):
 
     def clip_grad_norm(self, max_norm, aggregate_norm_fn=None):
         """Clips gradient norm."""
+        if hasattr(self.cfg, "msamp") and self.cfg.msamp:
+            return msamp.clip_grad_norm_(self.params, max_norm)
         return utils.clip_grad_norm_(self.params, max_norm, aggregate_norm_fn)
 
     def step(self, closure=None, scale=1.0, groups=None):
diff --git a/fairseq/trainer.py b/fairseq/trainer.py
index da1f9491..ec6e1732 100644
--- a/fairseq/trainer.py
+++ b/fairseq/trainer.py
@@ -18,6 +18,7 @@ from typing import Any, Dict, List
 
 import torch
 from omegaconf import OmegaConf
+import msamp
 
 from fairseq import checkpoint_utils, models, optim, utils
 from fairseq.dataclass.configs import FairseqConfig
@@ -115,6 +116,14 @@ class Trainer(object):
         ):
             self._criterion = self._criterion.to(device=self.device)
             self._model = self._model.to(device=self.device)
+
+        if self.cfg.common.msamp:
+            logger.info(f"msamp is enabled, opt level is {self.cfg.common.msamp_opt_level}")
+            assert self._model is not None
+            self._model = msamp.nn.LinearReplacer.replace(self._model)
+            # self._model, _ = msamp.initialize(self._model, None, self.cfg.common.msamp_opt_level)
+            logger.info(f"FP8 model is: {self._model}")
+
         self.pipeline_model_parallel = cfg.distributed_training.pipeline_model_parallel
         self.last_device = None
         if self.cuda and self.pipeline_model_parallel:
diff --git a/fairseq_cli/train.py b/fairseq_cli/train.py
index 376bd1d0..75197bc0 100644
--- a/fairseq_cli/train.py
+++ b/fairseq_cli/train.py
@@ -26,6 +26,7 @@ logger = logging.getLogger("fairseq_cli.train")
 import numpy as np
 import torch
 from omegaconf import DictConfig, OmegaConf
+from fvcore.nn import FlopCountAnalysis
 
 from fairseq import checkpoint_utils, options, quantization_utils, tasks, utils
 from fairseq.data import data_utils, iterators
@@ -123,6 +124,16 @@ def main(cfg: FairseqConfig) -> None:
         )
     )
 
+    # compute model flops: create fake input and use fvcore to compute the model flops.
+    tokens_per_sample = cfg.task.tokens_per_sample
+    logger.info(f'tokens_per_sample: {tokens_per_sample}')
+    token_ids = [0] + [100] * (tokens_per_sample - 2) + [2]
+    src_tokens = torch.tensor(token_ids).unsqueeze(0).cuda()
+    with torch.no_grad():
+        model.cuda()
+        model_flops = FlopCountAnalysis(model, src_tokens).total()
+    logger.info(f'model flops: {model_flops}')
+
     # Load valid dataset (we load training data below, based on the latest checkpoint)
     # We load the valid dataset AFTER building the model
     data_utils.raise_if_valid_subsets_unintentionally_ignored(cfg)
@@ -187,7 +198,7 @@ def main(cfg: FairseqConfig) -> None:
             break
 
         # train for one epoch
-        valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
+        valid_losses, should_stop = train(cfg, trainer, task, epoch_itr, model_flops)
         if should_stop:
             break
 
@@ -244,7 +255,7 @@ def should_stop_early(cfg: DictConfig, valid_loss: float) -> bool:
 
 @metrics.aggregate("train")
 def train(
-    cfg: DictConfig, trainer: Trainer, task: tasks.FairseqTask, epoch_itr
+    cfg: DictConfig, trainer: Trainer, task: tasks.FairseqTask, epoch_itr, model_flops=0
 ) -> Tuple[List[Optional[float]], bool]:
     """Train the model for one epoch and return validation losses."""
     # Initialize data iterator
@@ -320,6 +331,12 @@ def train(
             num_updates = trainer.get_num_updates()
             if num_updates % cfg.common.log_interval == 0:
                 stats = get_training_stats(metrics.get_smoothed_values("train_inner"))
+                throughput = stats["bsz"] * stats["ups"]
+                stats["throughput"] = throughput
+                throughput_per_gpu = throughput / cfg.distributed_training.distributed_world_size
+                # The reason of x 3: 1 forward + 2 backward. The reason of x 2: 1MACs = 2FLOPs
+                stats["tflops"] = throughput_per_gpu * 3 * 2 * model_flops / 1e12
+
                 progress.log(stats, tag="train_inner", step=num_updates)
 
                 # reset mid-epoch stats after each log interval
diff --git a/setup.py b/setup.py
index 8a9b2f97..1bc5650d 100644
--- a/setup.py
+++ b/setup.py
@@ -187,7 +187,6 @@ def do_setup(package_data):
             "torch>=1.10",
             "tqdm",
             "bitarray",
-            "torchaudio>=0.8.0",
         ],
         extras_require={
             "dev": ["flake8", "pytest", "black==22.3.0"],
