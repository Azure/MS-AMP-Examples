diff --git a/engine.py b/engine.py
index ed10cea..9fb4dd5 100644
--- a/engine.py
+++ b/engine.py
@@ -15,6 +15,9 @@ from timm.utils import accuracy, ModelEma
 from losses import DistillationLoss
 import utils
 
+import os
+sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), '../../'))
+from common.te_utils import TeUtils
 
 def train_one_epoch(model: torch.nn.Module, criterion: DistillationLoss,
                     data_loader: Iterable, optimizer: torch.optim.Optimizer,
@@ -22,11 +25,14 @@ def train_one_epoch(model: torch.nn.Module, criterion: DistillationLoss,
                     model_ema: Optional[ModelEma] = None, mixup_fn: Optional[Mixup] = None,
                     set_training_mode=True, args = None):
     model.train(set_training_mode)
-    metric_logger = utils.MetricLogger(delimiter="  ")
+    metric_logger = utils.MetricLogger(delimiter="  ", flops=args.flops)
     metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))
     header = 'Epoch: [{}]'.format(epoch)
     print_freq = 10
 
+    # amp_enable, fp8_enable, fp8_format='hybrid', max_history_len=1, amax_compute_algo='max'
+    autocast_context = TeUtils.get_autocast(True, args.enable_te_fp8)
+
     for samples, targets in metric_logger.log_every(data_loader, print_freq, header):
         samples = samples.to(device, non_blocking=True)
         targets = targets.to(device, non_blocking=True)
@@ -37,7 +43,7 @@ def train_one_epoch(model: torch.nn.Module, criterion: DistillationLoss,
         if args.bce_loss:
             targets = targets.gt(0.0).type(targets.dtype)
                     
-        with torch.cuda.amp.autocast():
+        with autocast_context():
             outputs = model(samples)
             loss = criterion(samples, outputs, targets)
 
@@ -51,7 +57,7 @@ def train_one_epoch(model: torch.nn.Module, criterion: DistillationLoss,
 
         # this attribute is added by timm on one optimizer (adahessian)
         is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order
-        loss_scaler(loss, optimizer, clip_grad=max_norm,
+        loss_scaler(loss, model, optimizer, clip_grad=max_norm,
                     parameters=model.parameters(), create_graph=is_second_order)
 
         torch.cuda.synchronize()
@@ -67,7 +73,7 @@ def train_one_epoch(model: torch.nn.Module, criterion: DistillationLoss,
 
 
 @torch.no_grad()
-def evaluate(data_loader, model, device):
+def evaluate(data_loader, model, device, args):
     criterion = torch.nn.CrossEntropyLoss()
 
     metric_logger = utils.MetricLogger(delimiter="  ")
@@ -75,13 +81,14 @@ def evaluate(data_loader, model, device):
 
     # switch to evaluation mode
     model.eval()
+    autocast_context = TeUtils.get_autocast(True, args.enable_te_fp8)
 
     for images, target in metric_logger.log_every(data_loader, 10, header):
         images = images.to(device, non_blocking=True)
         target = target.to(device, non_blocking=True)
 
         # compute output
-        with torch.cuda.amp.autocast():
+        with autocast_context():
             output = model(images)
             loss = criterion(output, target)
 
diff --git a/main.py b/main.py
index bc8c418..98de2a9 100644
--- a/main.py
+++ b/main.py
@@ -15,7 +15,9 @@ from timm.models import create_model
 from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy
 from timm.scheduler import create_scheduler
 from timm.optim import create_optimizer
-from timm.utils import NativeScaler, get_state_dict, ModelEma
+from timm.utils import get_state_dict, ModelEma
+import msamp
+from scaler import NativeScalerWithGradReduce
 
 from datasets import build_dataset
 from engine import train_one_epoch, evaluate
@@ -28,6 +30,12 @@ import models_v2
 
 import utils
 
+import os
+import sys
+sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), '../../'))
+
+from fvcore.nn import FlopCountAnalysis
+from common.te_utils import replace_with_telinear
 
 def get_args_parser():
     parser = argparse.ArgumentParser('DeiT training and evaluation script', add_help=False)
@@ -181,6 +189,13 @@ def get_args_parser():
     parser.add_argument('--world_size', default=1, type=int,
                         help='number of distributed processes')
     parser.add_argument('--dist_url', default='env://', help='url used to set up distributed training')
+
+    # msamp parameters
+    parser.add_argument('--enable-msamp', action='store_true', default=False, help='enable MS-AMP')
+    parser.add_argument('--msamp-opt-level', type=str, default='O1', help='MS-AMP optimization level')
+
+    # transformer engine
+    parser.add_argument("--enable-te-fp8", action='store_true', default=False, help='enable TE-FP8')
     return parser
 
 
@@ -205,6 +220,8 @@ def main(args):
     dataset_train, args.nb_classes = build_dataset(is_train=True, args=args)
     dataset_val, _ = build_dataset(is_train=False, args=args)
 
+    first_image = dataset_train[0][0]
+
     if True:  # args.distributed:
         num_tasks = utils.get_world_size()
         global_rank = utils.get_rank()
@@ -266,6 +283,12 @@ def main(args):
         img_size=args.input_size
     )
 
+    input = first_image.unsqueeze(0)
+    flops = FlopCountAnalysis(model, input).total()
+    args.flops = flops
+
+    if args.enable_msamp or args.enable_te_fp8:
+        model.head.use_fp32_linear = True
                     
     if args.finetune:
         if args.finetune.startswith('https'):
@@ -336,17 +359,33 @@ def main(args):
             device='cpu' if args.model_ema_force_cpu else '',
             resume='')
 
+    if not args.unscale_lr:
+        linear_scaled_lr = args.lr * args.batch_size * utils.get_world_size() / 512.0
+        args.lr = linear_scaled_lr
+
+    if args.enable_te_fp8:
+        print("te-fp8 is enabled")
+        assert not args.enable_msamp, 'msamp and te-fp8 cannot be enabled at the same time'
+        model = replace_with_telinear(model)
+
+    optimizer = create_optimizer(args, model)
+
+    if args.enable_msamp:
+        print(f'msamp is enabled, opt_level: {args.msamp_opt_level}')
+        model, optimizer = msamp.initialize(model, optimizer, args.msamp_opt_level)
+
+    if utils.get_rank() == 0:
+        print(f'type of optimizer is {type(optimizer)}')
+        print(f'model is {model}')
+
     model_without_ddp = model
     if args.distributed:
         model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])
         model_without_ddp = model.module
     n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)
     print('number of params:', n_parameters)
-    if not args.unscale_lr:
-        linear_scaled_lr = args.lr * args.batch_size * utils.get_world_size() / 512.0
-        args.lr = linear_scaled_lr
-    optimizer = create_optimizer(args, model_without_ddp)
-    loss_scaler = NativeScaler()
+
+    loss_scaler = NativeScalerWithGradReduce()
 
     lr_scheduler, _ = create_scheduler(args, optimizer)
 
@@ -406,7 +445,7 @@ def main(args):
                 loss_scaler.load_state_dict(checkpoint['scaler'])
         lr_scheduler.step(args.start_epoch)
     if args.eval:
-        test_stats = evaluate(data_loader_val, model, device)
+        test_stats = evaluate(data_loader_val, model, device, args)
         print(f"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%")
         return
 
@@ -434,13 +473,13 @@ def main(args):
                     'optimizer': optimizer.state_dict(),
                     'lr_scheduler': lr_scheduler.state_dict(),
                     'epoch': epoch,
-                    'model_ema': get_state_dict(model_ema),
+                    'model_ema': get_state_dict(model_ema) if model_ema else None,
                     'scaler': loss_scaler.state_dict(),
                     'args': args,
                 }, checkpoint_path)
              
 
-        test_stats = evaluate(data_loader_val, model, device)
+        test_stats = evaluate(data_loader_val, model, device, args)
         print(f"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%")
         
         if max_accuracy < test_stats["acc1"]:
@@ -453,7 +492,7 @@ def main(args):
                         'optimizer': optimizer.state_dict(),
                         'lr_scheduler': lr_scheduler.state_dict(),
                         'epoch': epoch,
-                        'model_ema': get_state_dict(model_ema),
+                        'model_ema': get_state_dict(model_ema) if model_ema else None,
                         'scaler': loss_scaler.state_dict(),
                         'args': args,
                     }, checkpoint_path)
diff --git a/models.py b/models.py
index 5b22ef3..9919678 100644
--- a/models.py
+++ b/models.py
@@ -10,7 +10,7 @@ from timm.models.layers import trunc_normal_
 
 
 __all__ = [
-    'deit_tiny_patch16_224', 'deit_small_patch16_224', 'deit_base_patch16_224',
+    'deit_tiny_patch16_224', 'deit_small_patch16_224', 'deit_base_patch16_224', 'deit_large_patch16_224',
     'deit_tiny_distilled_patch16_224', 'deit_small_distilled_patch16_224',
     'deit_base_distilled_patch16_224', 'deit_base_patch16_384',
     'deit_base_distilled_patch16_384',
@@ -103,6 +103,14 @@ def deit_base_patch16_224(pretrained=False, **kwargs):
         model.load_state_dict(checkpoint["model"])
     return model
 
+@register_model
+def deit_large_patch16_224(pretrained=False, **kwargs):
+    model = VisionTransformer(
+        patch_size=16, embed_dim=2048, depth=24, num_heads=32, mlp_ratio=4, qkv_bias=True,
+        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)
+    assert not pretrained
+    model.default_cfg = _cfg()
+    return model
 
 @register_model
 def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):
diff --git a/scaler.py b/scaler.py
new file mode 100644
index 0000000..dba0819
--- /dev/null
+++ b/scaler.py
@@ -0,0 +1,28 @@
+
+import torch
+from msamp import clip_grad_norm_
+
+
+class NativeScalerWithGradReduce:
+    state_dict_key = "amp_scaler"
+
+    def __init__(self):
+        self._scaler = torch.cuda.amp.GradScaler()
+
+    def __call__(self, loss, model, optimizer, clip_grad=None, clip_mode='norm', parameters=None, create_graph=False):
+        self._scaler.scale(loss).backward(create_graph=create_graph)
+        if hasattr(optimizer, 'all_reduce_grads'):
+            optimizer.all_reduce_grads(model)
+        if clip_grad is not None:
+            assert parameters is not None
+            self._scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params in-place
+            assert clip_mode == 'norm'
+            clip_grad_norm_(parameters, clip_grad)
+        self._scaler.step(optimizer)
+        self._scaler.update()
+
+    def state_dict(self):
+        return self._scaler.state_dict()
+
+    def load_state_dict(self, state_dict):
+        self._scaler.load_state_dict(state_dict)
\ No newline at end of file
diff --git a/utils.py b/utils.py
index d1064f6..67d02eb 100644
--- a/utils.py
+++ b/utils.py
@@ -14,7 +14,6 @@ import datetime
 import torch
 import torch.distributed as dist
 
-
 class SmoothedValue(object):
     """Track a series of values and provide access to smoothed values over a
     window or the global series average.
@@ -78,9 +77,10 @@ class SmoothedValue(object):
 
 
 class MetricLogger(object):
-    def __init__(self, delimiter="\t"):
+    def __init__(self, delimiter="\t", flops=0):
         self.meters = defaultdict(SmoothedValue)
         self.delimiter = delimiter
+        self.flops = flops
 
     def update(self, **kwargs):
         for k, v in kwargs.items():
@@ -127,16 +127,26 @@ class MetricLogger(object):
             'eta: {eta}',
             '{meters}',
             'time: {time}',
-            'data: {data}'
+            'data: {data}',
+            'throughput: {throughput}',
+            'tflops: {tflops:.2f}'
         ]
         if torch.cuda.is_available():
             log_msg.append('max mem: {memory:.0f}')
+
         log_msg = self.delimiter.join(log_msg)
         MB = 1024.0 * 1024.0
+
         for obj in iterable:
             data_time.update(time.time() - end)
             yield obj
+
+            batch_size = obj[0].shape[0]
             iter_time.update(time.time() - end)
+            throughput = int(batch_size / iter_time.value)
+            # First mutiply by 3: 1 for forward, 2 for backward. Then multiply by 2: 1MACs = 2FLOPs
+            tflops = 3 * 2 * self.flops * throughput / 1e12
+
             if i % print_freq == 0 or i == len(iterable) - 1:
                 eta_seconds = iter_time.global_avg * (len(iterable) - i)
                 eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))
@@ -145,7 +155,10 @@ class MetricLogger(object):
                         i, len(iterable), eta=eta_string,
                         meters=str(self),
                         time=str(iter_time), data=str(data_time),
-                        memory=torch.cuda.max_memory_allocated() / MB))
+                        throughput=throughput,
+                        tflops=tflops,
+                        memory=torch.cuda.max_memory_allocated() / MB,
+                        ))
                 else:
                     print(log_msg.format(
                         i, len(iterable), eta=eta_string,
